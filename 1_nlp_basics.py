# -*- coding: utf-8 -*-
"""1.NLP Basics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y2ufPkbDim_wYl_LbTUmOjeBMxkavrz7

# Tokenization
"""

import spacy

spacy.load(name = 'en_core_web_sm')

!python -m spacy download en_core_web_sm

import en_core_web_sm
nlp = en_core_web_sm.load()

"""spacy can easily change any sentence into token."""

s1 = 'Apple is looking at buying U.K. startup for $1 billion !'
s2 = 'Hello all, We are here to help you! email support@udemy.com or visit us at http://www.udemy.com!'
s3 = '10km cab ride almost costs $20 in NYC'
s4 = "Let's watch a movie together."

doc1 = nlp(s1)
print(s1)
for token in doc1:
  print(token)

"""# Stemming


"""

words = ['playing', 'plays', 'played', 'easily','quickly']

import nltk

"""Porter stemmer and snowball stemmer are these two stemmer can use to detect the root the token."""

from nltk.stem import PorterStemmer
from nltk.stem.snowball import SnowballStemmer

p_stemmer = PorterStemmer()
s_stemmer = SnowballStemmer(language='english')

print('Token','---->','P_stemmer','----->', 'S_stemmer')
for token in words:
  print(token,'---->' , p_stemmer.stem(token), '----->', s_stemmer.stem(token))

"""# Lemmatization"""

import spacy
nlp = spacy.load('en_core_web_sm')

doc1 = nlp('Thank you for considering my application.'
'I look forward to the opportunity to discuss how my skills and experiences align with the needs of your team.'
'Please find my resume attached for your review.')

for token in doc1:
  print(token, '\t', token.lemma_)

for word in doc1.split():
  print(word + ' ------  ' +p_stemmer.stem(word))